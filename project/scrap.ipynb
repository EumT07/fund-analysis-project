{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b980d66d",
   "metadata": {},
   "source": [
    "## Customer info requirements\n",
    "\n",
    "At a high level the process is to:\n",
    "1. Go to this website: https://www.cefconnect.com/\n",
    "2. Enter a stock symbol\n",
    "3. Go to the Pricing History page\n",
    "4. Select the data for a specific month\n",
    "5. Copy and paste the resulting data into a Google Sheet that Iâ€™ll provide.\n",
    "\n",
    "Deliverables\n",
    "Delivery of a Google Sheet with pricing data for all the 206 funds listed and for the 12 months requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395dab3",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9d81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional, Any, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b921e9",
   "metadata": {},
   "source": [
    "### Data and link to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434a52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.cefconnect.com/\"\n",
    "fund_name_list = [\"ACP\",\"FOF\",\"EVT\"]\n",
    "funds_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c87ce",
   "metadata": {},
   "source": [
    "### Running the Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scrap:\n",
    "    \"\"\"Class to handle web scraping of fund data from CEF Connect website.\"\"\"\n",
    "    \n",
    "    def __init__(self, url: str, fund_names: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the scraper with target URL and fund names.\n",
    "        \n",
    "        Args:\n",
    "            url: The website URL to scrape\n",
    "            fund_names: List of fund symbols to search for\n",
    "        \"\"\"\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.months = list(range(1, 13))\n",
    "        self.current_month = datetime.datetime.now().month\n",
    "        self.fund_name_list = fund_names\n",
    "        self.current_fund_name: Optional[str] = None\n",
    "        self.funds_list: List[Dict[str, str]] = []\n",
    "        self.url = url\n",
    "        \n",
    "        # Start the scraping process\n",
    "        self.running()\n",
    "    \n",
    "    def running(self) -> None:\n",
    "        \"\"\"Main method to run the scraping process.\"\"\"\n",
    "        try:\n",
    "            # Start browser and navigate to URL\n",
    "            self.driver.get(self.url)\n",
    "            \n",
    "            # Wait for page to load\n",
    "            self.driver.implicitly_wait(10)\n",
    "            \n",
    "            # Accept cookies banner if present\n",
    "            cookies_close = self.driver.find_element(By.ID, \"onetrust-accept-btn-handler\")\n",
    "            \n",
    "            if cookies_close:\n",
    "                time.sleep(5)\n",
    "                cookies_close.click()\n",
    "\n",
    "            # Check if fund list is empty\n",
    "            if len(self.fund_name_list) <= 0:\n",
    "                print(\"Fund List is empty\")\n",
    "                return\n",
    "\n",
    "            # Process each fund in the list\n",
    "            for fund in self.fund_name_list:\n",
    "                time.sleep(5)\n",
    "                self.current_fund_name = fund\n",
    "                self.search_fund(fund)\n",
    "                    \n",
    "        except Exception as error:\n",
    "            print(f\"Error - Running: {error}\")\n",
    "\n",
    "    def search_fund(self, fund: str) -> None:\n",
    "        \"\"\"\n",
    "        Search for a specific fund and extract its pricing data.\n",
    "        \n",
    "        Args:\n",
    "            fund: Fund symbol to search for\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Find search input and enter fund name\n",
    "            input_element = self.driver.find_element(By.ID, \"quick-search-input-primary\")\n",
    "            input_element.clear()\n",
    "            \n",
    "            time.sleep(5)\n",
    "            input_element.send_keys(fund)\n",
    "\n",
    "            # Click search button\n",
    "            time.sleep(5)\n",
    "            self.driver.find_element(By.TAG_NAME, \"button\").click()\n",
    "\n",
    "            # Navigate to pricing section\n",
    "            time.sleep(5)\n",
    "            self.driver.find_element(By.XPATH, \"//a[@href='#pricing']\").click()\n",
    "            \n",
    "            # Extract data for each month up to current month\n",
    "            for month in self.months:\n",
    "                if month <= 3:\n",
    "                    time.sleep(2)\n",
    "                    monthly_data = self.get_month(month)\n",
    "                    if monthly_data:\n",
    "                        self.funds_list.extend(monthly_data)\n",
    "\n",
    "        except Exception as error:\n",
    "            print(f\"Error - Searching fund {fund}: {error}\")\n",
    "\n",
    "    def get_month(self, month: int, day: str = '01') -> Optional[List[Dict[str, str]]]:\n",
    "        \"\"\"\n",
    "        Extract pricing data for a specific month.\n",
    "        \n",
    "        Args:\n",
    "            month: Month number (1-12)\n",
    "            day: Day of month (default: '01')\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing fund data for the specified month\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Find date input field\n",
    "            date_input = self.driver.find_element(By.XPATH, '//*[@id=\"dp-phistory-date\"]')\n",
    "            \n",
    "            time.sleep(4)\n",
    "            \n",
    "            # Format date and set it in the input field\n",
    "            date_required = f'{month:02d}/{day}/2025'\n",
    "            script = \"\"\"\n",
    "                arguments[0].removeAttribute('readonly');\n",
    "                arguments[0].value = arguments[1]\n",
    "            \"\"\"\n",
    "            self.driver.execute_script(script, date_input, date_required)\n",
    "            time.sleep(5)\n",
    "\n",
    "            # Click search button to load data\n",
    "            go_btn = self.driver.find_element(By.XPATH, '//*[@id=\"btn-pricing-history\"]')\n",
    "            go_btn.click()\n",
    "\n",
    "            # Extract table data\n",
    "            time.sleep(5)\n",
    "            table_element = self.driver.find_element(By.XPATH, '//*[@id=\"pricing-history\"]/tbody')\n",
    "            html_content = table_element.get_attribute('innerHTML')\n",
    "\n",
    "            data_table = self.get_funds_data(html_content) #type: ignore\n",
    "        \n",
    "            # Display extracted data\n",
    "            print({\n",
    "                \"Month\": f'{month:02d}/{day}/2025',\n",
    "                \"Data\": data_table\n",
    "            })\n",
    "\n",
    "            return data_table\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(f\"Error - getting month {month}: {error}\")\n",
    "            return None\n",
    "\n",
    "    def get_funds_data(self, html: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Parse HTML table content and extract fund data.\n",
    "        \n",
    "        Args:\n",
    "            html: HTML content of the table\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing parsed fund data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            time.sleep(2)\n",
    "            rows = soup.find_all('tr')\n",
    "            data = []\n",
    "\n",
    "            if not rows:\n",
    "                print(\"No data found: table info\")\n",
    "                return []\n",
    "\n",
    "            # Process each row in the table\n",
    "            for row in rows:\n",
    "                cells = row.find_all(\"td\")\n",
    "\n",
    "                if not cells:\n",
    "                    continue\n",
    "                    \n",
    "                row_data = self._create_data_dict(cells)\n",
    "                data.append(row_data)\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as error:\n",
    "            print(f\"Error - getting data from table: {error}\")\n",
    "            return []\n",
    "\n",
    "    def _create_data_dict(self, data_cells: List[Any]) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Create a dictionary from table row data.\n",
    "        \n",
    "        Args:\n",
    "            data_cells: List of table cell elements\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing fund data for one row\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if len(data_cells) < 4:\n",
    "                return {\"Error\": \"Empty row in the table\"}\n",
    "            \n",
    "            result = {\n",
    "                \"symbol\": self.current_fund_name,\n",
    "                \"date\": data_cells[0].get_text(strip=True),\n",
    "                \"share_price\": data_cells[1].get_text(strip=True),\n",
    "                \"NAV\": data_cells[2].get_text(strip=True),\n",
    "                \"Premiun|Discount\": data_cells[3].get_text(strip=True)\n",
    "            }\n",
    "            return result\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(f\"Error - Creating data dictionary: {error}\")\n",
    "            return {\"Error\": f\"Failed to parse row data: {error}\"}\n",
    "\n",
    "# Execute the scraper\n",
    "run = Scrap(url, fund_name_list)\n",
    "funds_data = run.funds_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4e119",
   "metadata": {},
   "source": [
    "### Total data obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada1602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(funds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7f46c",
   "metadata": {},
   "source": [
    "### Getting Excel or CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_csv_xlxs(file,funds):\n",
    "    try:\n",
    "        \n",
    "        # Make folder\n",
    "        folder_path = \"./files\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        # root\n",
    "        root = f\"{folder_path}/{file}\"\n",
    "\n",
    "        data = {\n",
    "            \"Symbol\":[],\n",
    "            \"Date\":[],\n",
    "            \"Share_Price\":[],\n",
    "            \"Premiun|Discount\":[],\n",
    "        }\n",
    "\n",
    "        for x in funds:\n",
    "            data[\"Symbol\"].append(x.get(\"symbol\",\"None\"))\n",
    "            data[\"Date\"].append(x.get(\"date\",\"None\"))\n",
    "            data[\"Share_Price\"].append(x.get(\"share_price\",\"None\"))\n",
    "            data[\"Premiun|Discount\"].append(x.get(\"Premiun|Discount\",\"None\"))\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_excel(f\"{root}.xlsx\",engine='openpyxl',index=False, sheet_name='funds')\n",
    "        df.to_csv(f\"{root}.csv\",index=False, sep=\";\",encoding='utf-8-sig')\n",
    "\n",
    "        print(\"Done\")\n",
    "        \n",
    "    except Exception as error:\n",
    "        print(f\"Error CSV: {error}\")\n",
    "\n",
    "get_csv_xlxs(\"Funds\",funds_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
